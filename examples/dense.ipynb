{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brest Cancer Wisconsin Dataset Example\n",
    "\n",
    "This Jupyter Notebook demonstrates how to build and use a neural network with dense layers to process and classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from src.preprocessing import DataLoader, min_max_scaler, train_test_split\n",
    "from src.loss import BinaryCrossentropy\n",
    "from src.encode import BinaryEncoder\n",
    "from src.optimizer import Adam\n",
    "from src.scheduler import CosineScheduler\n",
    "from src.tensor import Tensor\n",
    "from src.structure import Layer, Dense, Dropout, LeakyRelu, Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is small, so it's faster to use CPU\n",
    "Tensor.set_default_device(\"cpu\")\n",
    "\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy(dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(np.unique(y))\n",
    "\n",
    "# Normalize data\n",
    "data = min_max_scaler(X, -1, 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "data_train, excepted_train, data_test, expected_test = train_test_split(data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Layer):\n",
    "    def __init__(self) -> None:\n",
    "        self.layers = [\n",
    "            Dense(len(X[0])),\n",
    "            LeakyRelu(),\n",
    "            Dense(32),\n",
    "            LeakyRelu(),\n",
    "            Dropout(0.2),\n",
    "            Dense(16),\n",
    "            LeakyRelu(),\n",
    "            Dense(8),\n",
    "            LeakyRelu(),\n",
    "            Dense(1),\n",
    "            Sigmoid(),\n",
    "        ]\n",
    "\n",
    "        self.encoder = BinaryEncoder(classes)\n",
    "\n",
    "    def __call__(self, inputs: Tensor) -> Tensor:\n",
    "        return inputs.sequential(self.layers)\n",
    "\n",
    "    def train(self, steps: int) -> None:\n",
    "        data = DataLoader(data_train, excepted_train, batch_size=4)\n",
    "\n",
    "        opt = Adam(list(self.parameters), CosineScheduler(learning_rate=1e-2, min_lr=1e-9, max_steps=100, cyclic=True))\n",
    "\n",
    "        loss_func = BinaryCrossentropy()\n",
    "\n",
    "        for _ in range(steps):\n",
    "            x, y = next(data)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss = loss_func(self(x), self.encoder(y))\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            print(f\"loss: {loss.mean()}\")\n",
    "\n",
    "    @Tensor.no_grad()\n",
    "    def evaluate(self, data: Tensor, expected: Tensor) -> float:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            total += 1\n",
    "\n",
    "            if self.encoder.decode(self(data[i])) == expected[i].item():\n",
    "                correct += 1\n",
    "\n",
    "        return correct / total\n",
    "\n",
    "nn = Model()\n",
    "\n",
    "nn.train(len(data_train) * 4)\n",
    "\n",
    "print(f\"test: {nn.evaluate(data_test, expected_test)},train: {nn.evaluate(data_train, excepted_train)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
