{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brest Cancer Wisconsin Dataset Example\n",
    "\n",
    "This Jupyter Notebook demonstrates how to build and use a neural network with dense layers to process and classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from src import NeuralNetwork\n",
    "\n",
    "from src.preprocessing import min_max_scaler, train_test_split\n",
    "from src.core import Tensor\n",
    "from src.activation import LeakyRelu, Sigmoid\n",
    "from src.loss import BinaryCrossentropy\n",
    "from src.optimizer import Adam\n",
    "from src.scheduler import CosineScheduler\n",
    "from src.config import FeedForwardConfig, TrainingConfig\n",
    "from src.structure import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "X = Tensor(X.to_numpy())\n",
    "y = Tensor(y.to_numpy(dtype=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(np.unique(y))\n",
    "\n",
    "# Normalize data\n",
    "data = min_max_scaler(X, 0, 1)\n",
    "\n",
    "# Combine data and labels into a structured array\n",
    "combined = Tensor([(d, label[0]) for d, label in zip(data, y)], dtype=object)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train, test = train_test_split(combined, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FeedForwardConfig(\n",
    "    network_structure=[\n",
    "        Dense(len(X[0])),\n",
    "        Dropout(p=0.1),\n",
    "        Dense(32),\n",
    "        Dropout(p=0.1),\n",
    "        Dense(16),\n",
    "        Dropout(p=0.1),\n",
    "        Dense(8),\n",
    "        Dense(1)\n",
    "    ],\n",
    "    classes=classes,\n",
    "    hidden_activation=LeakyRelu(),\n",
    "    output_activation=Sigmoid(),\n",
    ")\n",
    "\n",
    "nn = NeuralNetwork(config)\n",
    "\n",
    "nn.train(\n",
    "    list(train),\n",
    "    list(test),\n",
    "    config=TrainingConfig(\n",
    "        lr=CosineScheduler(learning_rate=0.001, min_lr=0.0001, max_steps=20, cyclic=True),\n",
    "        patience_stop=100,\n",
    "        loss=BinaryCrossentropy(),\n",
    "        optimizer=Adam(),\n",
    "        batch_size=4,\n",
    "        debug=True,\n",
    "        store=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"final test: {nn.evaluate(list(combined))}, test: {nn.evaluate(list(test))}, train: {nn.evaluate(list(train))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
