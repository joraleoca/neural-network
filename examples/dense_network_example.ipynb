{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brest Cancer Wisconsin Dataset Example\n",
    "\n",
    "This Jupyter Notebook demonstrates how to build and use a neural network with dense layers to process and classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from src import NeuralNetwork, Config\n",
    "\n",
    "from src.preprocessing import min_max_scaler, train_test_split\n",
    "from src.activation import LeakyRelu, Sigmoid\n",
    "from src.loss import BinaryCrossentropy\n",
    "from src.optimizer import Adam\n",
    "from src.scheduler import CosineScheduler\n",
    "from src.config import FeedForwardConfig, TrainingConfig\n",
    "from src.structure import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is too small to use GPU\n",
    "Config.set_default_device(\"cpu\")\n",
    "\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy(dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(np.unique(y))\n",
    "\n",
    "# Normalize data\n",
    "data = min_max_scaler(X, 0, 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "data_train, excepted_train, data_test, expected_test = train_test_split(data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FeedForwardConfig(\n",
    "    network_structure=[\n",
    "        Dense(len(X[0])),\n",
    "        Dense(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16),\n",
    "        Dense(8),\n",
    "        Dense(1),\n",
    "    ],\n",
    "    classes=classes,\n",
    "    hidden_activation=LeakyRelu(),\n",
    "    output_activation=Sigmoid(),\n",
    ")\n",
    "\n",
    "nn = NeuralNetwork(config)\n",
    "\n",
    "nn.train(\n",
    "    data_train,\n",
    "    excepted_train,\n",
    "    data_test,\n",
    "    expected_test,\n",
    "    config=TrainingConfig(\n",
    "        lr=CosineScheduler(\n",
    "            learning_rate=0.01, min_lr=0.0001, max_steps=100, cyclic=True\n",
    "        ),\n",
    "        patience_stop=100,\n",
    "        loss=BinaryCrossentropy(),\n",
    "        optimizer=Adam(),\n",
    "        batch_size=4,\n",
    "        debug=True,\n",
    "        store=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"final test: {nn.evaluate(data, y)},\"\n",
    "    f\"test: {nn.evaluate(data_test, expected_test)},\"\n",
    "    f\"train: {nn.evaluate(data_train, excepted_train)}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
