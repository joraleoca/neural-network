{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from neural_network import NeuralNetwork\n",
    "\n",
    "from preprocessing import min_max_scaler, train_test_split\n",
    "from activation import LeakyRelu, Softmax, Sigmoid, Relu\n",
    "from loss import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from optimizer import Adam, SGD\n",
    "from scheduler import FactorScheduler, CosineScheduler  \n",
    "from config import NeuralNetworkConfig, TrainingConfig\n",
    "from regularization import Dropout\n",
    "from core import ParameterLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy(dtype=str)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(np.unique(y))\n",
    "\n",
    "# Normalize data\n",
    "data = min_max_scaler(X, -1, 1)\n",
    "\n",
    "# Combine data and labels into a structured array\n",
    "combined = np.array([(d, label[0]) for d, label in zip(data, y)], dtype=object)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train, test = train_test_split(combined, random_state=0)\n",
    "\n",
    "classes, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NeuralNetworkConfig(\n",
    "    network_structure=[len(X[0]), 16, 8, len(classes)],\n",
    "    classes=classes,\n",
    "    hidden_activation=LeakyRelu(),\n",
    "    output_activation=Softmax(),\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    optimizer=SGD(momentum=0.9, nesterov=True),\n",
    "    batch_size=4,\n",
    "    dropout=Dropout(p=0.1), \n",
    "    loader=None\n",
    ")\n",
    "\n",
    "nn = NeuralNetwork(config)\n",
    "\n",
    "nn.train(\n",
    "    list(train),\n",
    "    list(test),\n",
    "    TrainingConfig(\n",
    "        lr=CosineScheduler(max_steps=100),\n",
    "        patience_stop=100,\n",
    "        debug=True,\n",
    "        store=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"final test: {nn.evaluate(list(combined))}, test: {nn.evaluate(list(test))}, train: {nn.evaluate(list(train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NeuralNetworkConfig(\n",
    "    network_structure=[len(X[0]), 16, 8, 1],\n",
    "    classes=classes,\n",
    "    hidden_activation=LeakyRelu(),\n",
    "    output_activation=Sigmoid(),\n",
    "    loss=BinaryCrossentropy(),\n",
    "    optimizer=Adam(),\n",
    "    batch_size=4,\n",
    "    dropout=Dropout(p=0.1), \n",
    "    loader=None\n",
    ")\n",
    "\n",
    "nn = NeuralNetwork(config)\n",
    "\n",
    "nn.train(\n",
    "    list(train),\n",
    "    list(test),\n",
    "    TrainingConfig(\n",
    "        lr=CosineScheduler(learning_rate=0.001, min_lr=0.0001, max_steps=20, cyclic=True),\n",
    "        patience_stop=100,\n",
    "        debug=True,\n",
    "        store=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"final test: {nn.evaluate(list(combined))}, test: {nn.evaluate(list(test))}, train: {nn.evaluate(list(train))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
